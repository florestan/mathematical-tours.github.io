\contentsline {chapter}{\numberline {1}Shannon Theory}{7}{chapter.1}
\contentsline {section}{\numberline {1.1}Analog vs. Discrete Signals}{7}{section.1.1}
\contentsline {subsection}{\numberline {1.1.1}Acquisition and Sampling}{7}{subsection.1.1.1}
\contentsline {subsection}{\numberline {1.1.2}Linear Translation Invariant Sampler}{8}{subsection.1.1.2}
\contentsline {section}{\numberline {1.2}Shannon Sampling Theorem}{9}{section.1.2}
\contentsline {paragraph}{Reminders about Fourier transform.}{9}{section*.3}
\contentsline {paragraph}{Reminders about Fourier series.}{9}{section*.4}
\contentsline {paragraph}{Poisson formula.}{10}{section*.5}
\contentsline {paragraph}{Shannon theorem.}{10}{section*.6}
\contentsline {paragraph}{Quantization.}{12}{section*.7}
\contentsline {section}{\numberline {1.3}Shannon Source Coding Theorem}{13}{section.1.3}
\contentsline {paragraph}{Uniform coding.}{13}{section*.8}
\contentsline {paragraph}{Prefix coding.}{13}{section*.9}
\contentsline {paragraph}{Probabilistic modeling.}{14}{section*.10}
\contentsline {paragraph}{Shannon theorem.}{15}{section*.11}
\contentsline {paragraph}{Doing better.}{17}{section*.12}
\contentsline {chapter}{\numberline {2}Fourier Transforms}{19}{chapter.2}
\contentsline {section}{\numberline {2.1}Hilbert spaces and Fourier Transforms}{19}{section.2.1}
\contentsline {subsection}{\numberline {2.1.1}Hilbertian bases.}{19}{subsection.2.1.1}
\contentsline {subsection}{\numberline {2.1.2}Fourier basis on $\mathbb {R}/2\pi \mathbb {Z}$.}{20}{subsection.2.1.2}
\contentsline {section}{\numberline {2.2}Convolution on $\mathbb {R}$ and $\mathbb {T}$}{21}{section.2.2}
\contentsline {subsection}{\numberline {2.2.1}Convolution}{21}{subsection.2.2.1}
\contentsline {subsection}{\numberline {2.2.2}Translation Invariant Operators}{22}{subsection.2.2.2}
\contentsline {subsection}{\numberline {2.2.3}Revisiting Poisson formula using distributions.}{24}{subsection.2.2.3}
\contentsline {section}{\numberline {2.3}Finite Fourier Transform and Convolution}{25}{section.2.3}
\contentsline {subsection}{\numberline {2.3.1}Discrete Ortho-bases}{25}{subsection.2.3.1}
\contentsline {subsection}{\numberline {2.3.2}Discrete Fourier transform}{26}{subsection.2.3.2}
\contentsline {subsection}{\numberline {2.3.3}Fast Fourier transform}{26}{subsection.2.3.3}
\contentsline {subsection}{\numberline {2.3.4}Finite convolution}{27}{subsection.2.3.4}
\contentsline {section}{\numberline {2.4}Discretisation Issues}{28}{section.2.4}
\contentsline {subsection}{\numberline {2.4.1}Fourier approximation via spatial zero padding.}{28}{subsection.2.4.1}
\contentsline {subsection}{\numberline {2.4.2}Fourier interpolation via spectral zero padding.}{28}{subsection.2.4.2}
\contentsline {section}{\numberline {2.5}Fourier in Multiple Dimensions}{29}{section.2.5}
\contentsline {subsection}{\numberline {2.5.1}On Continuous Domains}{29}{subsection.2.5.1}
\contentsline {paragraph}{On $\mathbb {R}^d$.}{29}{figure.2.13}
\contentsline {paragraph}{On $(\mathbb {R}/2\pi \mathbb {Z})^d$.}{30}{section*.14}
\contentsline {subsection}{\numberline {2.5.2}On Discrete Domains}{31}{subsection.2.5.2}
\contentsline {paragraph}{Discrete Fourier Transform.}{31}{figure.2.16}
\contentsline {paragraph}{Fast Fourier Transform.}{31}{section*.16}
\contentsline {subsection}{\numberline {2.5.3}Shannon sampling theorem.}{32}{subsection.2.5.3}
\contentsline {subsection}{\numberline {2.5.4}Convolution in higher dimension.}{32}{subsection.2.5.4}
\contentsline {section}{\numberline {2.6}Application to ODEs and PDEs}{32}{section.2.6}
\contentsline {subsection}{\numberline {2.6.1}On Continuous Domains}{32}{subsection.2.6.1}
\contentsline {subsection}{\numberline {2.6.2}Finite Domain and Discretization}{33}{subsection.2.6.2}
\contentsline {section}{\numberline {2.7}A Bit of Group Theory}{33}{section.2.7}
\contentsline {subsection}{\numberline {2.7.1}Characters}{33}{subsection.2.7.1}
\contentsline {paragraph}{Commutative groups.}{34}{section*.17}
\contentsline {paragraph}{Discrete Fourier transform from character's point of view.}{35}{section*.18}
\contentsline {subsection}{\numberline {2.7.2}More General cases}{35}{subsection.2.7.2}
\contentsline {paragraph}{Infinite groups.}{35}{section*.19}
\contentsline {paragraph}{Non-commutative groups.}{35}{section*.20}
\contentsline {section}{\numberline {2.8}A Bit of Spectral Theory}{37}{section.2.8}
\contentsline {subsection}{\numberline {2.8.1}On a Surface or a Manifold}{37}{subsection.2.8.1}
\contentsline {subsection}{\numberline {2.8.2}Spherical Harmonics}{37}{subsection.2.8.2}
\contentsline {subsection}{\numberline {2.8.3}On a Graph}{37}{subsection.2.8.3}
\contentsline {subsection}{\numberline {2.8.4}Other things}{38}{subsection.2.8.4}
\contentsline {chapter}{\numberline {3}Wavelets}{39}{chapter.3}
\contentsline {section}{\numberline {3.1}Multi-resolution Approximation Spaces}{39}{section.3.1}
\contentsline {paragraph}{Scaling functions.}{39}{section*.21}
\contentsline {paragraph}{Spectral orthogonalization.}{40}{section*.22}
\contentsline {section}{\numberline {3.2}Multi-resolution Details Spaces}{41}{section.3.2}
\contentsline {paragraph}{Haar wavelets.}{42}{section*.23}
\contentsline {paragraph}{Shannon and splines.}{42}{section*.24}
\contentsline {section}{\numberline {3.3}On Bounded Domains}{43}{section.3.3}
\contentsline {section}{\numberline {3.4}Fast Wavelet Transform}{43}{section.3.4}
\contentsline {subsection}{\numberline {3.4.1}Discretization}{43}{subsection.3.4.1}
\contentsline {subsection}{\numberline {3.4.2}Forward Fast Wavelet Transform (FWT)}{44}{subsection.3.4.2}
\contentsline {paragraph}{Fast Haar transform.}{46}{section*.25}
\contentsline {subsection}{\numberline {3.4.3}Inverse Fast Transform (iFWT)}{47}{subsection.3.4.3}
\contentsline {section}{\numberline {3.5}2-D Wavelets}{49}{section.3.5}
\contentsline {subsection}{\numberline {3.5.1}Anisotropic Wavelets}{49}{subsection.3.5.1}
\contentsline {subsection}{\numberline {3.5.2}Isotropic Wavelets}{49}{subsection.3.5.2}
\contentsline {paragraph}{Haar 2-D multiresolution.}{51}{section*.26}
\contentsline {paragraph}{Discrete 2-D wavelet coefficients.}{51}{section*.27}
\contentsline {paragraph}{Forward 2-D wavelet transform basic step.}{51}{section*.28}
\contentsline {paragraph}{Fast 2-D wavelet transform.}{52}{section*.29}
\contentsline {paragraph}{Fast 2-D inverse wavelet transform.}{53}{section*.30}
\contentsline {section}{\numberline {3.6}Wavelet Design}{54}{section.3.6}
\contentsline {subsection}{\numberline {3.6.1}Low-pass Filter Constraints}{54}{subsection.3.6.1}
\contentsline {subsection}{\numberline {3.6.2}High-pass Filter Constraints}{56}{subsection.3.6.2}
\contentsline {paragraph}{Quadrature mirror filters.}{57}{section*.31}
\contentsline {subsection}{\numberline {3.6.3}Wavelet Design Constraints}{58}{subsection.3.6.3}
\contentsline {paragraph}{Vanishing moments.}{58}{section*.32}
\contentsline {paragraph}{Support.}{59}{section*.33}
\contentsline {paragraph}{Smoothness.}{59}{section*.34}
\contentsline {subsection}{\numberline {3.6.4}Daubechies Wavelets}{60}{subsection.3.6.4}
\contentsline {paragraph}{Wavelet display.}{61}{section*.35}
\contentsline {chapter}{\numberline {4}Linear and Non-linear Approximation}{63}{chapter.4}
\contentsline {section}{\numberline {4.1}Approximation}{63}{section.4.1}
\contentsline {subsection}{\numberline {4.1.1}Approximation in an Ortho-basis}{63}{subsection.4.1.1}
\contentsline {subsection}{\numberline {4.1.2}Linear Approximation}{63}{subsection.4.1.2}
\contentsline {subsection}{\numberline {4.1.3}Non-linear Approximation}{64}{subsection.4.1.3}
\contentsline {paragraph}{Computation of the threshold.}{64}{section*.36}
\contentsline {paragraph}{Hard thresholding.}{65}{section*.37}
\contentsline {section}{\numberline {4.2}Signal and Image Modeling}{65}{section.4.2}
\contentsline {subsection}{\numberline {4.2.1}Uniformly Smooth Signals and Images}{65}{subsection.4.2.1}
\contentsline {paragraph}{Signals with derivatives.}{65}{section*.38}
\contentsline {paragraph}{Sobolev smooth signals and images.}{66}{section*.39}
\contentsline {subsection}{\numberline {4.2.2}Piecewise Regular Signals and Images}{67}{subsection.4.2.2}
\contentsline {paragraph}{Piecewise smooth signals.}{67}{section*.40}
\contentsline {paragraph}{Piecewise smooth images.}{67}{section*.41}
\contentsline {subsection}{\numberline {4.2.3}Bounded Variation Signals and Images}{67}{subsection.4.2.3}
\contentsline {subsection}{\numberline {4.2.4}Cartoon Images}{68}{subsection.4.2.4}
\contentsline {section}{\numberline {4.3}Efficient approximation}{68}{section.4.3}
\contentsline {subsection}{\numberline {4.3.1}Decay of Approximation Error}{68}{subsection.4.3.1}
\contentsline {paragraph}{Polynomial error decay.}{69}{section*.42}
\contentsline {paragraph}{Relevance for compression, denoising and inverse problems.}{69}{section*.43}
\contentsline {paragraph}{Comparison of signals.}{69}{section*.44}
\contentsline {subsection}{\numberline {4.3.2}Comparison of bases.}{69}{subsection.4.3.2}
\contentsline {section}{\numberline {4.4}Fourier Linear Approximation of Smooth Functions}{70}{section.4.4}
\contentsline {subsection}{\numberline {4.4.1}1-D Fourier Approximation}{70}{subsection.4.4.1}
\contentsline {paragraph}{Low pass approximation.}{71}{section*.45}
\contentsline {subsection}{\numberline {4.4.2}Sobolev Images}{73}{subsection.4.4.2}
\contentsline {section}{\numberline {4.5}Wavelet Approximation of Piecewise Smooth Functions}{73}{section.4.5}
\contentsline {subsection}{\numberline {4.5.1}Decay of Wavelet Coefficients}{73}{subsection.4.5.1}
\contentsline {subsection}{\numberline {4.5.2}1-D Piecewise Smooth Approximation}{74}{subsection.4.5.2}
\contentsline {paragraph}{Step 1. Coefficient segmentation.}{75}{section*.46}
\contentsline {paragraph}{Step 2. Counting the error.}{75}{section*.47}
\contentsline {paragraph}{Step 3. Counting the number of measurements.}{76}{section*.48}
\contentsline {paragraph}{Step 3. Putting everything together.}{76}{section*.49}
\contentsline {subsection}{\numberline {4.5.3}2-D Piecewise Smooth Approximation}{77}{subsection.4.5.3}
\contentsline {section}{\numberline {4.6}Cartoon Images Approximation}{77}{section.4.6}
\contentsline {subsection}{\numberline {4.6.1}Wavelet Approximation of Cartoon Images}{78}{subsection.4.6.1}
\contentsline {subsection}{\numberline {4.6.2}Finite Element Approximation}{78}{subsection.4.6.2}
\contentsline {subsection}{\numberline {4.6.3}Curvelets Approximation}{79}{subsection.4.6.3}
\contentsline {paragraph}{Curvelets.}{80}{section*.50}
\contentsline {paragraph}{Parameter discretization.}{81}{section*.51}
\contentsline {paragraph}{Curvelet tight frame.}{81}{section*.52}
\contentsline {paragraph}{Curvelet approximation.}{81}{section*.53}
\contentsline {chapter}{\numberline {5}Compression}{83}{chapter.5}
\contentsline {section}{\numberline {5.1}Transform Coding}{83}{section.5.1}
\contentsline {subsection}{\numberline {5.1.1}Coding}{83}{subsection.5.1.1}
\contentsline {subsection}{\numberline {5.1.2}De-coding}{84}{subsection.5.1.2}
\contentsline {subsection}{\numberline {5.1.3}Support Coding}{84}{subsection.5.1.3}
\contentsline {paragraph}{Signals constraints.}{85}{section*.54}
\contentsline {paragraph}{Discrete computation and scaling of $N$.}{85}{section*.55}
\contentsline {paragraph}{Support coding.}{85}{section*.56}
\contentsline {paragraph}{Values coding.}{85}{section*.57}
\contentsline {paragraph}{Total number of bits.}{86}{section*.58}
\contentsline {section}{\numberline {5.2}Entropic Coding}{86}{section.5.2}
\contentsline {paragraph}{Probabilistic modeling.}{87}{section*.59}
\contentsline {paragraph}{Huffman code.}{87}{section*.60}
\contentsline {section}{\numberline {5.3}JPEG-2000}{87}{section.5.3}
\contentsline {paragraph}{Dyadic quantization.}{88}{section*.61}
\contentsline {paragraph}{Steam packing.}{88}{section*.62}
\contentsline {paragraph}{Bit plane coding pass.}{88}{section*.63}
\contentsline {paragraph}{Contextual coder.}{88}{section*.64}
\contentsline {chapter}{\numberline {6}Denoising}{91}{chapter.6}
\contentsline {section}{\numberline {6.1}Noise Modeling}{91}{section.6.1}
\contentsline {subsection}{\numberline {6.1.1}Noise in Images}{91}{subsection.6.1.1}
\contentsline {subsection}{\numberline {6.1.2}Image Formation}{92}{subsection.6.1.2}
\contentsline {paragraph}{Additive Noise.}{92}{section*.65}
\contentsline {subsection}{\numberline {6.1.3}Denoiser}{93}{subsection.6.1.3}
\contentsline {section}{\numberline {6.2}Linear Denoising using Filtering}{93}{section.6.2}
\contentsline {subsection}{\numberline {6.2.1}Translation Invariant Estimators}{93}{subsection.6.2.1}
\contentsline {subsection}{\numberline {6.2.2}Optimal Filter Selection}{94}{subsection.6.2.2}
\contentsline {subsection}{\numberline {6.2.3}Wiener Filter}{94}{subsection.6.2.3}
\contentsline {subsection}{\numberline {6.2.4}Denoising and Linear Approximation}{95}{subsection.6.2.4}
\contentsline {section}{\numberline {6.3}Non-linear Denoising using Thresholding}{98}{section.6.3}
\contentsline {subsection}{\numberline {6.3.1}Hard Thresholding}{98}{subsection.6.3.1}
\contentsline {subsection}{\numberline {6.3.2}Soft Thresholding}{99}{subsection.6.3.2}
\contentsline {paragraph}{Coarse scale management.}{100}{section*.66}
\contentsline {paragraph}{Empirical choice of the threshold.}{100}{section*.67}
\contentsline {subsection}{\numberline {6.3.3}Minimax Optimality of Thresholding}{100}{subsection.6.3.3}
\contentsline {paragraph}{Sparse coefficients estimation.}{100}{section*.68}
\contentsline {paragraph}{Universal threshold value.}{101}{section*.69}
\contentsline {paragraph}{Asymptotic optimality.}{101}{section*.70}
\contentsline {subsection}{\numberline {6.3.4}Translation Invariant Thresholding Estimators}{102}{subsection.6.3.4}
\contentsline {paragraph}{Translation invariance.}{102}{section*.71}
\contentsline {paragraph}{Cycle spinning.}{103}{section*.72}
\contentsline {paragraph}{Translation invariant wavelet frame.}{103}{section*.73}
\contentsline {subsection}{\numberline {6.3.5}Exotic Thresholdings}{104}{subsection.6.3.5}
\contentsline {paragraph}{Semi-soft thresholding.}{105}{section*.74}
\contentsline {paragraph}{Stein thresholding.}{105}{section*.75}
\contentsline {subsection}{\numberline {6.3.6}Block Thresholding}{105}{subsection.6.3.6}
\contentsline {section}{\numberline {6.4}Data-dependant Noises}{107}{section.6.4}
\contentsline {subsection}{\numberline {6.4.1}Poisson Noise}{108}{subsection.6.4.1}
\contentsline {paragraph}{Poisson model.}{108}{section*.76}
\contentsline {paragraph}{Variance stabilization.}{109}{section*.77}
\contentsline {subsection}{\numberline {6.4.2}Multiplicative Noise}{111}{subsection.6.4.2}
\contentsline {paragraph}{Multiplicative image formation.}{111}{section*.78}
\contentsline {chapter}{\numberline {7}Variational Priors and Regularization}{115}{chapter.7}
\contentsline {section}{\numberline {7.1}Sobolev and Total Variation Priors}{115}{section.7.1}
\contentsline {subsection}{\numberline {7.1.1}Continuous Priors}{115}{subsection.7.1.1}
\contentsline {paragraph}{Sobolev prior.}{115}{section*.79}
\contentsline {paragraph}{Total variation prior.}{115}{section*.80}
\contentsline {subsection}{\numberline {7.1.2}Discrete Priors}{115}{subsection.7.1.2}
\contentsline {paragraph}{Discrete gradient.}{116}{section*.81}
\contentsline {paragraph}{Discrete divergence.}{116}{section*.82}
\contentsline {paragraph}{Discrete laplacian.}{117}{section*.83}
\contentsline {paragraph}{Discrete energies.}{118}{section*.84}
\contentsline {section}{\numberline {7.2}PDE and Energy Minimization}{118}{section.7.2}
\contentsline {subsection}{\numberline {7.2.1}General Flows}{118}{subsection.7.2.1}
\contentsline {subsection}{\numberline {7.2.2}Heat Flow}{118}{subsection.7.2.2}
\contentsline {paragraph}{Continuous in space.}{119}{section*.85}
\contentsline {paragraph}{Discrete in space.}{119}{section*.86}
\contentsline {subsection}{\numberline {7.2.3}Total Variation Flows}{119}{subsection.7.2.3}
\contentsline {paragraph}{Total variation gradient.}{119}{section*.87}
\contentsline {paragraph}{Regularized total variation.}{120}{section*.88}
\contentsline {paragraph}{Regularized total variation flow.}{121}{section*.89}
\contentsline {subsection}{\numberline {7.2.4}PDE Flows for Denoising}{121}{subsection.7.2.4}
\contentsline {section}{\numberline {7.3}Regularization for Denoising}{122}{section.7.3}
\contentsline {subsection}{\numberline {7.3.1}Regularization}{122}{subsection.7.3.1}
\contentsline {subsection}{\numberline {7.3.2}Sobolev Regularization}{123}{subsection.7.3.2}
\contentsline {subsection}{\numberline {7.3.3}TV Regularization}{124}{subsection.7.3.3}
\contentsline {chapter}{\numberline {8}Inverse Problems}{127}{chapter.8}
\contentsline {section}{\numberline {8.1}Inverse Problems Regularization}{127}{section.8.1}
\contentsline {paragraph}{Denoising.}{127}{section*.90}
\contentsline {paragraph}{De-blurring and super-resolution.}{127}{section*.91}
\contentsline {paragraph}{Interpolation and inpainting.}{128}{section*.92}
\contentsline {paragraph}{Medical imaging.}{128}{section*.93}
\contentsline {paragraph}{Regression for supervised learning.}{128}{section*.94}
\contentsline {section}{\numberline {8.2}Theoretical Study of Quadratic Regularization}{129}{section.8.2}
\contentsline {subsection}{\numberline {8.2.1}Singular Value Decomposition}{129}{subsection.8.2.1}
\contentsline {paragraph}{Finite dimension.}{129}{section*.95}
\contentsline {paragraph}{Compact operators.}{130}{section*.96}
\contentsline {paragraph}{Pseudo inverse.}{130}{section*.97}
\contentsline {subsection}{\numberline {8.2.2}Tikonov Regularization}{131}{subsection.8.2.2}
\contentsline {paragraph}{Regularized inverse.}{131}{section*.98}
\contentsline {paragraph}{Variational regularization.}{131}{section*.99}
\contentsline {paragraph}{Source condition.}{132}{section*.100}
\contentsline {paragraph}{Sublinear convergence speed.}{132}{section*.101}
\contentsline {section}{\numberline {8.3}Quadratic Regularization}{134}{section.8.3}
\contentsline {paragraph}{Convex regularization.}{134}{section*.102}
\contentsline {paragraph}{Quadratic Regularization.}{135}{section*.103}
\contentsline {paragraph}{Example of convolution.}{135}{section*.104}
\contentsline {subsection}{\numberline {8.3.1}Solving Linear System}{136}{subsection.8.3.1}
\contentsline {section}{\numberline {8.4}Non-Quadratic Regularization}{136}{section.8.4}
\contentsline {subsection}{\numberline {8.4.1}Total Variation Regularization}{136}{subsection.8.4.1}
\contentsline {paragraph}{Total variation.}{137}{section*.105}
\contentsline {paragraph}{Discretized Total variation.}{137}{section*.106}
\contentsline {subsection}{\numberline {8.4.2}Gradient Descent Method}{138}{subsection.8.4.2}
\contentsline {subsection}{\numberline {8.4.3}Examples of Gradient Computation}{138}{subsection.8.4.3}
\contentsline {section}{\numberline {8.5}Examples of Inverse Problems}{139}{section.8.5}
\contentsline {subsection}{\numberline {8.5.1}Deconvolution}{139}{subsection.8.5.1}
\contentsline {subsection}{\numberline {8.5.2}Inpainting}{139}{subsection.8.5.2}
\contentsline {subsection}{\numberline {8.5.3}Tomography Inversion}{140}{subsection.8.5.3}
\contentsline {chapter}{\numberline {9}Sparse Regularization}{145}{chapter.9}
\contentsline {section}{\numberline {9.1}Sparsity Priors}{145}{section.9.1}
\contentsline {subsection}{\numberline {9.1.1}Ideal sparsity prior.}{145}{subsection.9.1.1}
\contentsline {subsection}{\numberline {9.1.2}Convex relaxation}{145}{subsection.9.1.2}
\contentsline {subsection}{\numberline {9.1.3}Sparse Regularization and Thresholding}{146}{subsection.9.1.3}
\contentsline {section}{\numberline {9.2}Sparse Regularization of Inverse Problems}{148}{section.9.2}
\contentsline {paragraph}{Analysis vs. synthesis priors.}{148}{section*.107}
\contentsline {section}{\numberline {9.3}Iterative Soft Thresholding Algorithm}{148}{section.9.3}
\contentsline {subsection}{\numberline {9.3.1}Noiseless Recovery as a Linear Program}{149}{subsection.9.3.1}
\contentsline {subsection}{\numberline {9.3.2}Projected Gradient Descent for $\ell ^1$.}{149}{subsection.9.3.2}
\contentsline {subsection}{\numberline {9.3.3}Iterative Soft Thresholding and Forward Backward}{150}{subsection.9.3.3}
\contentsline {section}{\numberline {9.4}Example: Sparse Deconvolution}{151}{section.9.4}
\contentsline {subsection}{\numberline {9.4.1}Sparse Spikes Deconvolution}{151}{subsection.9.4.1}
\contentsline {subsection}{\numberline {9.4.2}Sparse Wavelets Deconvolution}{151}{subsection.9.4.2}
\contentsline {subsection}{\numberline {9.4.3}Sparse Inpainting}{152}{subsection.9.4.3}
\contentsline {chapter}{\numberline {10}Theory of Sparse Regularization}{157}{chapter.10}
\contentsline {section}{\numberline {10.1}Existence and Uniqueness}{157}{section.10.1}
\contentsline {subsection}{\numberline {10.1.1}Existence}{157}{subsection.10.1.1}
\contentsline {subsection}{\numberline {10.1.2}Polytope Projection for the Constraint Problem}{157}{subsection.10.1.2}
\contentsline {subsection}{\numberline {10.1.3}Optimality Conditions}{159}{subsection.10.1.3}
\contentsline {subsection}{\numberline {10.1.4}Uniqueness}{160}{subsection.10.1.4}
\contentsline {subsection}{\numberline {10.1.5}Duality}{161}{subsection.10.1.5}
\contentsline {section}{\numberline {10.2}Consistency and Sparsitency}{162}{section.10.2}
\contentsline {subsection}{\numberline {10.2.1}Bregman Divergence Rates for General Regularizations}{162}{subsection.10.2.1}
\contentsline {subsection}{\numberline {10.2.2}Linear Rates in Norms for $\ell ^1$ Regularization}{164}{subsection.10.2.2}
\contentsline {subsection}{\numberline {10.2.3}Sparsistency for Low Noise}{165}{subsection.10.2.3}
\contentsline {subsection}{\numberline {10.2.4}Sparsistency for Arbitrary Noise}{168}{subsection.10.2.4}
\contentsline {section}{\numberline {10.3}Sparse Deconvolution Case Study}{168}{section.10.3}
\contentsline {chapter}{\numberline {11}Compressed Sensing}{173}{chapter.11}
\contentsline {section}{\numberline {11.1}Motivation and Potential Applications}{173}{section.11.1}
\contentsline {subsection}{\numberline {11.1.1}Single Pixel Camera}{173}{subsection.11.1.1}
\contentsline {subsection}{\numberline {11.1.2}Sparse Recovery}{174}{subsection.11.1.2}
\contentsline {section}{\numberline {11.2}Dual Certificate Theory and Non-Uniform Guarantees}{175}{section.11.2}
\contentsline {subsection}{\numberline {11.2.1}Random Projection of Polytopes}{175}{subsection.11.2.1}
\contentsline {subsection}{\numberline {11.2.2}Random Matrices}{175}{subsection.11.2.2}
\contentsline {paragraph}{Linear growth $P = s/\beta $. }{175}{section*.108}
\contentsline {paragraph}{Super-linear grows $P = s \qopname \relax o{log}(\ldots )$. }{175}{section*.109}
\contentsline {subsection}{\numberline {11.2.3}Dual Certificates}{177}{subsection.11.2.3}
\contentsline {paragraph}{Coherence-based analysis.}{177}{section*.110}
\contentsline {paragraph}{Randomized analysis of the Fuchs certificate.}{178}{section*.111}
\contentsline {section}{\numberline {11.3}RIP Theory for Uniform Guarantees}{180}{section.11.3}
\contentsline {subsection}{\numberline {11.3.1}Restricted Isometry Constants}{180}{subsection.11.3.1}
\contentsline {subsection}{\numberline {11.3.2}RIP implies dual certificates}{181}{subsection.11.3.2}
\contentsline {subsection}{\numberline {11.3.3}RIP implies stable recovery}{183}{subsection.11.3.3}
\contentsline {subsection}{\numberline {11.3.4}Fourier sampling RIP}{184}{subsection.11.3.4}
\contentsline {chapter}{\numberline {12}Basics of Machine Learning}{187}{chapter.12}
\contentsline {section}{\numberline {12.1}Unsupervised Learning}{187}{section.12.1}
\contentsline {subsection}{\numberline {12.1.1}Dimensionality Reduction and PCA}{187}{subsection.12.1.1}
\contentsline {paragraph}{Presentation of the method.}{187}{section*.112}
\contentsline {paragraph}{Optimality analysis.}{188}{section*.113}
\contentsline {subsection}{\numberline {12.1.2}Clustering and $k$-means}{191}{subsection.12.1.2}
\contentsline {paragraph}{$k$-means}{191}{section*.114}
\contentsline {paragraph}{$k$-means++}{191}{section*.115}
\contentsline {paragraph}{Lloyd algorithm and continuous densities.}{192}{section*.116}
\contentsline {section}{\numberline {12.2}Empirical Risk Minimization}{192}{section.12.2}
\contentsline {subsection}{\numberline {12.2.1}Empirical Risk}{193}{subsection.12.2.1}
\contentsline {subsection}{\numberline {12.2.2}Prediction and Consistency}{193}{subsection.12.2.2}
\contentsline {subsection}{\numberline {12.2.3}Parametric Approaches and Regularization}{194}{subsection.12.2.3}
\contentsline {paragraph}{Prediction vs. estimation risks.}{194}{section*.117}
\contentsline {subsection}{\numberline {12.2.4}Testing Set and Cross-validation}{194}{subsection.12.2.4}
\contentsline {section}{\numberline {12.3}Supervised Learning: Regression}{194}{section.12.3}
\contentsline {subsection}{\numberline {12.3.1}Linear Regression}{195}{subsection.12.3.1}
\contentsline {paragraph}{Least square and conditional expectation.}{195}{section*.118}
\contentsline {paragraph}{Penalized linear models.}{196}{figure.12.10}
\contentsline {paragraph}{Ridge regression (quadratic penalization).}{197}{section*.120}
\contentsline {section}{\numberline {12.4}Supervised Learning: Classification}{197}{section.12.4}
\contentsline {subsection}{\numberline {12.4.1}Nearest Neighbors Classification}{197}{subsection.12.4.1}
\contentsline {subsection}{\numberline {12.4.2}Two Classes Logistic Classification}{198}{subsection.12.4.2}
\contentsline {paragraph}{Approximate risk minimization.}{198}{section*.121}
\contentsline {paragraph}{Logistic loss probabilistic interpretation.}{199}{section*.122}
\contentsline {paragraph}{Gradient descent method.}{200}{section*.123}
\contentsline {subsection}{\numberline {12.4.3}Multi-Classes Logistic Classification}{201}{subsection.12.4.3}
\contentsline {section}{\numberline {12.5}Kernel Methods}{202}{section.12.5}
\contentsline {subsection}{\numberline {12.5.1}Feature Map and Kernels}{203}{subsection.12.5.1}
\contentsline {subsection}{\numberline {12.5.2}Kernel Design}{204}{subsection.12.5.2}
\contentsline {paragraph}{Kernel on non-Euclidean spaces.}{204}{section*.124}
\contentsline {subsection}{\numberline {12.5.3}General Case}{205}{subsection.12.5.3}
\contentsline {section}{\numberline {12.6}Probably approximately correct learning theory}{206}{section.12.6}
\contentsline {subsection}{\numberline {12.6.1}Non parametric setup and calibration}{207}{subsection.12.6.1}
\contentsline {paragraph}{Risk decomposition}{207}{section*.125}
\contentsline {paragraph}{Calibration in the classification setup}{207}{section*.126}
\contentsline {subsection}{\numberline {12.6.2}PAC bounds}{208}{subsection.12.6.2}
\contentsline {paragraph}{Bias-variance decomposition.}{208}{section*.127}
\contentsline {paragraph}{Approximation error.}{208}{section*.128}
\contentsline {paragraph}{Estimation error.}{208}{section*.129}
\contentsline {chapter}{\numberline {13}Optimization \& Machine Learning: Smooth Optimization}{211}{chapter.13}
\contentsline {section}{\numberline {13.1}Motivation in Machine Learning}{211}{section.13.1}
\contentsline {subsection}{\numberline {13.1.1}Unconstraint optimization}{211}{subsection.13.1.1}
\contentsline {subsection}{\numberline {13.1.2}Regression}{212}{subsection.13.1.2}
\contentsline {subsection}{\numberline {13.1.3}Classification}{212}{subsection.13.1.3}
\contentsline {section}{\numberline {13.2}Basics of Convex Analysis}{212}{section.13.2}
\contentsline {subsection}{\numberline {13.2.1}Existence of Solutions}{212}{subsection.13.2.1}
\contentsline {subsection}{\numberline {13.2.2}Convexity}{213}{subsection.13.2.2}
\contentsline {paragraph}{Strict convexity.}{213}{section*.130}
\contentsline {subsection}{\numberline {13.2.3}Convex Sets}{214}{subsection.13.2.3}
\contentsline {section}{\numberline {13.3}Derivative and gradient}{214}{section.13.3}
\contentsline {subsection}{\numberline {13.3.1}Gradient}{214}{subsection.13.3.1}
\contentsline {subsection}{\numberline {13.3.2}First Order Conditions}{215}{subsection.13.3.2}
\contentsline {subsection}{\numberline {13.3.3}Least Squares}{216}{subsection.13.3.3}
\contentsline {subsection}{\numberline {13.3.4}Link with PCA}{217}{subsection.13.3.4}
\contentsline {subsection}{\numberline {13.3.5}Classification}{218}{subsection.13.3.5}
\contentsline {subsection}{\numberline {13.3.6}Chain Rule}{218}{subsection.13.3.6}
\contentsline {section}{\numberline {13.4}Gradient Descent Algorithm}{219}{section.13.4}
\contentsline {subsection}{\numberline {13.4.1}Steepest Descent Direction}{219}{subsection.13.4.1}
\contentsline {subsection}{\numberline {13.4.2}Gradient Descent}{220}{subsection.13.4.2}
\contentsline {section}{\numberline {13.5}Convergence Analysis}{221}{section.13.5}
\contentsline {subsection}{\numberline {13.5.1}Quadratic Case}{221}{subsection.13.5.1}
\contentsline {paragraph}{Convergence analysis for the quadratic case.}{221}{section*.131}
\contentsline {subsection}{\numberline {13.5.2}General Case}{224}{subsection.13.5.2}
\contentsline {paragraph}{Hessian.}{224}{section*.132}
\contentsline {paragraph}{Smoothness and strong convexity.}{225}{section*.133}
\contentsline {paragraph}{Convergence analysis.}{226}{section*.134}
\contentsline {subsection}{\numberline {13.5.3}Acceleration}{227}{subsection.13.5.3}
\contentsline {chapter}{\numberline {14}Optimization \& Machine Learning: Advanced Topics}{229}{chapter.14}
\contentsline {section}{\numberline {14.1}Regularization}{229}{section.14.1}
\contentsline {subsection}{\numberline {14.1.1}Penalized Least Squares}{229}{subsection.14.1.1}
\contentsline {subsection}{\numberline {14.1.2}Ridge Regression}{229}{subsection.14.1.2}
\contentsline {paragraph}{Pseudo-inverse.}{230}{section*.135}
\contentsline {subsection}{\numberline {14.1.3}Lasso}{231}{subsection.14.1.3}
\contentsline {subsection}{\numberline {14.1.4}Iterative Soft Thresholding}{231}{subsection.14.1.4}
\contentsline {section}{\numberline {14.2}Stochastic Optimization}{232}{section.14.2}
\contentsline {subsection}{\numberline {14.2.1}Minimizing Sums and Expectation}{233}{subsection.14.2.1}
\contentsline {subsection}{\numberline {14.2.2}Batch Gradient Descent (BGD)}{233}{subsection.14.2.2}
\contentsline {subsection}{\numberline {14.2.3}Stochastic Gradient Descent (SGD)}{234}{subsection.14.2.3}
\contentsline {subsection}{\numberline {14.2.4}Stochastic Gradient Descent with Averaging (SGA)}{236}{subsection.14.2.4}
\contentsline {subsection}{\numberline {14.2.5}Stochastic Averaged Gradient Descent (SAG)}{237}{subsection.14.2.5}
\contentsline {section}{\numberline {14.3}Automatic Differentiation}{237}{section.14.3}
\contentsline {subsection}{\numberline {14.3.1}Finite Differences and Symbolic Calculus}{238}{subsection.14.3.1}
\contentsline {subsection}{\numberline {14.3.2}Computational Graphs}{238}{subsection.14.3.2}
\contentsline {subsection}{\numberline {14.3.3}Forward Mode of Automatic Differentiation}{238}{subsection.14.3.3}
\contentsline {paragraph}{Simple example.}{239}{section*.136}
\contentsline {paragraph}{Dual numbers.}{240}{section*.137}
\contentsline {subsection}{\numberline {14.3.4}Reverse Mode of Automatic Differentiation}{241}{subsection.14.3.4}
\contentsline {paragraph}{Back-propagation.}{241}{section*.138}
\contentsline {paragraph}{Simple example.}{241}{section*.139}
\contentsline {subsection}{\numberline {14.3.5}Feed-forward Compositions}{242}{subsection.14.3.5}
\contentsline {subsection}{\numberline {14.3.6}Feed-forward Architecture}{242}{subsection.14.3.6}
\contentsline {paragraph}{Multilayers perceptron.}{243}{section*.140}
\contentsline {paragraph}{Link with adjoint state method.}{243}{section*.141}
\contentsline {subsection}{\numberline {14.3.7}Recurrent Architectures}{244}{subsection.14.3.7}
\contentsline {paragraph}{Residual recurrent networks. }{244}{section*.142}
\contentsline {paragraph}{Mitigating memory requirement. }{244}{section*.143}
\contentsline {paragraph}{Fixed point maps}{245}{section*.144}
\contentsline {paragraph}{Argmin layers}{245}{section*.145}
\contentsline {paragraph}{Sinkhorn's algorithm}{246}{section*.146}
\contentsline {chapter}{\numberline {15}Deep Learning}{247}{chapter.15}
\contentsline {section}{\numberline {15.1}Multi-Layers Perceptron}{247}{section.15.1}
\contentsline {subsection}{\numberline {15.1.1}MLP and its derivative}{247}{subsection.15.1.1}
\contentsline {paragraph}{Expressiveness. }{248}{section*.147}
\contentsline {subsection}{\numberline {15.1.2}MLP and Gradient Computation}{248}{subsection.15.1.2}
\contentsline {paragraph}{Optimizing with respect to $u$.}{248}{section*.148}
\contentsline {paragraph}{Optimizing with respect to $W$.}{248}{section*.149}
\contentsline {subsection}{\numberline {15.1.3}Universality}{249}{subsection.15.1.3}
\contentsline {paragraph}{Proof in dimension $p=1$.}{249}{section*.150}
\contentsline {paragraph}{Proof in arbitrary dimension $p$.}{249}{section*.151}
\contentsline {paragraph}{Quantitative rates.}{251}{section*.152}
\contentsline {section}{\numberline {15.2}Deep Discriminative Models}{251}{section.15.2}
\contentsline {subsection}{\numberline {15.2.1}Deep Network Structure}{251}{subsection.15.2.1}
\contentsline {subsection}{\numberline {15.2.2}Perceptron and Shallow Models}{252}{subsection.15.2.2}
\contentsline {subsection}{\numberline {15.2.3}Convolutional Neural Networks}{253}{subsection.15.2.3}
\contentsline {subsection}{\numberline {15.2.4}Scattering Transform}{254}{subsection.15.2.4}
\contentsline {chapter}{\numberline {16}Convex Analysis}{255}{chapter.16}
\contentsline {section}{\numberline {16.1}Basics of Convex Analysis}{255}{section.16.1}
\contentsline {subsection}{\numberline {16.1.1}Convex Sets and Functions}{255}{subsection.16.1.1}
\contentsline {subsection}{\numberline {16.1.2}First Order Conditions}{256}{subsection.16.1.2}
\contentsline {paragraph}{Existence of minimizers.}{256}{section*.153}
\contentsline {paragraph}{Sub-differential.}{256}{section*.154}
\contentsline {paragraph}{First Order Conditions.}{257}{section*.155}
\contentsline {paragraph}{Sub-differential calculus.}{257}{section*.156}
\contentsline {paragraph}{Normal cone.}{258}{section*.157}
\contentsline {section}{\numberline {16.2}Legendre-Fenchel Transform}{258}{section.16.2}
\contentsline {subsection}{\numberline {16.2.1}Legendre Transform}{259}{subsection.16.2.1}
\contentsline {subsection}{\numberline {16.2.2}Legendre transform and smoothness}{259}{subsection.16.2.2}
\contentsline {section}{\numberline {16.3}Convex Duality}{260}{section.16.3}
\contentsline {subsection}{\numberline {16.3.1}Lagrange Duality: Afine Constraint}{260}{subsection.16.3.1}
\contentsline {subsection}{\numberline {16.3.2}Lagrange Duality: General Case}{260}{subsection.16.3.2}
\contentsline {subsection}{\numberline {16.3.3}Fenchel-Rockafellar Duality}{262}{subsection.16.3.3}
\contentsline {chapter}{\numberline {17}Non-smooth Convex Optimization}{265}{chapter.17}
\contentsline {section}{\numberline {17.1}Descent Methods}{265}{section.17.1}
\contentsline {subsection}{\numberline {17.1.1}Gradient Descent}{265}{subsection.17.1.1}
\contentsline {subsection}{\numberline {17.1.2}Sub-gradient Descent}{265}{subsection.17.1.2}
\contentsline {subsection}{\numberline {17.1.3}Projected Gradient Descent}{266}{subsection.17.1.3}
\contentsline {section}{\numberline {17.2}Interior Point Methods}{266}{section.17.2}
\contentsline {section}{\numberline {17.3}Proximal Algorithm}{268}{section.17.3}
\contentsline {subsection}{\numberline {17.3.1}Proximal Map }{268}{subsection.17.3.1}
\contentsline {paragraph}{Examples}{268}{section*.158}
\contentsline {subsection}{\numberline {17.3.2}Basic Properties}{269}{subsection.17.3.2}
\contentsline {subsection}{\numberline {17.3.3}Related Concepts}{269}{subsection.17.3.3}
\contentsline {paragraph}{Link with sub-differential.}{269}{section*.159}
\contentsline {paragraph}{Link with duality.}{270}{section*.160}
\contentsline {paragraph}{Link with Moreau-Yosida regularization.}{270}{section*.161}
\contentsline {section}{\numberline {17.4}Proximal Gradient Algorithms}{270}{section.17.4}
\contentsline {subsection}{\numberline {17.4.1}Proximal Point Algorithm}{270}{subsection.17.4.1}
\contentsline {subsection}{\numberline {17.4.2}Forward-Backward}{271}{subsection.17.4.2}
\contentsline {paragraph}{Derivation using surrogate functionals.}{271}{section*.162}
\contentsline {paragraph}{Convergence of FB. }{272}{section*.163}
\contentsline {section}{\numberline {17.5}Primal-Dual Algorithms}{272}{section.17.5}
\contentsline {subsection}{\numberline {17.5.1}Forward-backward on the Dual}{272}{subsection.17.5.1}
\contentsline {subsection}{\numberline {17.5.2}Douglas-Rachford}{274}{subsection.17.5.2}
\contentsline {paragraph}{More than two functions.}{274}{section*.164}
\contentsline {paragraph}{Handling a linear operator.}{275}{section*.165}
\contentsline {subsection}{\numberline {17.5.3}Alternating Direction Method of Multipliers}{275}{subsection.17.5.3}
\contentsline {subsection}{\numberline {17.5.4}Primal-Dual Splitting}{277}{subsection.17.5.4}
