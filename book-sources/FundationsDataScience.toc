\contentsline {chapter}{\numberline {1}Shannon Theory}{11}{chapter.1}
\contentsline {section}{\numberline {1.1}Analog vs. Discrete Signals}{11}{section.1.1}
\contentsline {subsection}{\numberline {1.1.1}Acquisition and Sampling}{11}{subsection.1.1.1}
\contentsline {subsection}{\numberline {1.1.2}Linear Translation Invariant Sampler}{12}{subsection.1.1.2}
\contentsline {section}{\numberline {1.2}Shannon Sampling Theorem}{13}{section.1.2}
\contentsline {paragraph}{Reminders about Fourier transform.}{13}{section*.3}
\contentsline {paragraph}{Reminders about Fourier series.}{13}{section*.4}
\contentsline {paragraph}{Poisson formula.}{14}{section*.5}
\contentsline {paragraph}{Shannon theorem.}{14}{section*.6}
\contentsline {paragraph}{Quantization.}{16}{section*.7}
\contentsline {section}{\numberline {1.3}Shannon Source Coding Theorem}{17}{section.1.3}
\contentsline {paragraph}{Uniform coding.}{17}{section*.8}
\contentsline {paragraph}{Prefix coding.}{17}{section*.9}
\contentsline {paragraph}{Probabilistic modeling.}{18}{section*.10}
\contentsline {paragraph}{Shannon theorem.}{19}{section*.11}
\contentsline {paragraph}{Doing better.}{21}{section*.12}
\contentsline {chapter}{\numberline {2}Fourier Transforms}{23}{chapter.2}
\contentsline {section}{\numberline {2.1}Hilbert spaces and Fourier Transforms}{23}{section.2.1}
\contentsline {subsection}{\numberline {2.1.1}Hilbertian bases.}{23}{subsection.2.1.1}
\contentsline {subsection}{\numberline {2.1.2}Fourier basis on $\mathbb {R}/2\pi \mathbb {Z}$.}{24}{subsection.2.1.2}
\contentsline {section}{\numberline {2.2}Convolution on $\mathbb {R}$ and $\mathbb {T}$}{25}{section.2.2}
\contentsline {subsection}{\numberline {2.2.1}Convolution}{25}{subsection.2.2.1}
\contentsline {subsection}{\numberline {2.2.2}Translation Invariant Operators}{26}{subsection.2.2.2}
\contentsline {subsection}{\numberline {2.2.3}Revisiting Poisson formula using distributions.}{28}{subsection.2.2.3}
\contentsline {section}{\numberline {2.3}Finite Fourier Transform and Convolution}{29}{section.2.3}
\contentsline {subsection}{\numberline {2.3.1}Discrete Ortho-bases}{29}{subsection.2.3.1}
\contentsline {subsection}{\numberline {2.3.2}Discrete Fourier transform}{30}{subsection.2.3.2}
\contentsline {subsection}{\numberline {2.3.3}Fast Fourier transform}{30}{subsection.2.3.3}
\contentsline {subsection}{\numberline {2.3.4}Finite convolution}{31}{subsection.2.3.4}
\contentsline {section}{\numberline {2.4}Discretisation Issues}{32}{section.2.4}
\contentsline {subsection}{\numberline {2.4.1}Fourier approximation via spatial zero padding.}{32}{subsection.2.4.1}
\contentsline {subsection}{\numberline {2.4.2}Fourier interpolation via spectral zero padding.}{32}{subsection.2.4.2}
\contentsline {section}{\numberline {2.5}Fourier in Multiple Dimensions}{33}{section.2.5}
\contentsline {subsection}{\numberline {2.5.1}On Continuous Domains}{33}{subsection.2.5.1}
\contentsline {paragraph}{On $\mathbb {R}^d$.}{33}{figure.2.13}
\contentsline {paragraph}{On $(\mathbb {R}/2\pi \mathbb {Z})^d$.}{34}{section*.14}
\contentsline {subsection}{\numberline {2.5.2}On Discrete Domains}{35}{subsection.2.5.2}
\contentsline {paragraph}{Discrete Fourier Transform.}{35}{figure.2.16}
\contentsline {paragraph}{Fast Fourier Transform.}{35}{section*.16}
\contentsline {subsection}{\numberline {2.5.3}Shannon sampling theorem.}{36}{subsection.2.5.3}
\contentsline {subsection}{\numberline {2.5.4}Convolution in higher dimension.}{36}{subsection.2.5.4}
\contentsline {section}{\numberline {2.6}Application to ODEs and PDEs}{36}{section.2.6}
\contentsline {subsection}{\numberline {2.6.1}On Continuous Domains}{36}{subsection.2.6.1}
\contentsline {subsection}{\numberline {2.6.2}Finite Domain and Discretization}{37}{subsection.2.6.2}
\contentsline {section}{\numberline {2.7}A Bit of Group Theory}{37}{section.2.7}
\contentsline {subsection}{\numberline {2.7.1}Characters}{37}{subsection.2.7.1}
\contentsline {paragraph}{Commutative groups.}{38}{section*.17}
\contentsline {paragraph}{Discrete Fourier transform from character's point of view.}{39}{section*.18}
\contentsline {subsection}{\numberline {2.7.2}More General cases}{39}{subsection.2.7.2}
\contentsline {paragraph}{Infinite groups.}{39}{section*.19}
\contentsline {paragraph}{Non-commutative groups.}{39}{section*.20}
\contentsline {section}{\numberline {2.8}A Bit of Spectral Theory}{41}{section.2.8}
\contentsline {subsection}{\numberline {2.8.1}On a Surface or a Manifold}{41}{subsection.2.8.1}
\contentsline {subsection}{\numberline {2.8.2}Spherical Harmonics}{41}{subsection.2.8.2}
\contentsline {subsection}{\numberline {2.8.3}On a Graph}{41}{subsection.2.8.3}
\contentsline {subsection}{\numberline {2.8.4}Other things}{42}{subsection.2.8.4}
\contentsline {chapter}{\numberline {3}Wavelets}{43}{chapter.3}
\contentsline {section}{\numberline {3.1}Multi-resolution Approximation Spaces}{43}{section.3.1}
\contentsline {paragraph}{Scaling functions.}{43}{section*.21}
\contentsline {paragraph}{Spectral orthogonalization.}{44}{section*.22}
\contentsline {section}{\numberline {3.2}Multi-resolution Details Spaces}{45}{section.3.2}
\contentsline {paragraph}{Haar wavelets.}{46}{section*.23}
\contentsline {paragraph}{Shannon and splines.}{46}{section*.24}
\contentsline {section}{\numberline {3.3}On Bounded Domains}{47}{section.3.3}
\contentsline {section}{\numberline {3.4}Fast Wavelet Transform}{47}{section.3.4}
\contentsline {subsection}{\numberline {3.4.1}Discretization}{47}{subsection.3.4.1}
\contentsline {subsection}{\numberline {3.4.2}Forward Fast Wavelet Transform (FWT)}{48}{subsection.3.4.2}
\contentsline {paragraph}{Fast Haar transform.}{50}{section*.25}
\contentsline {subsection}{\numberline {3.4.3}Inverse Fast Transform (iFWT)}{51}{subsection.3.4.3}
\contentsline {section}{\numberline {3.5}2-D Wavelets}{53}{section.3.5}
\contentsline {subsection}{\numberline {3.5.1}Anisotropic Wavelets}{53}{subsection.3.5.1}
\contentsline {subsection}{\numberline {3.5.2}Isotropic Wavelets}{53}{subsection.3.5.2}
\contentsline {paragraph}{Haar 2-D multiresolution.}{55}{section*.26}
\contentsline {paragraph}{Discrete 2-D wavelet coefficients.}{55}{section*.27}
\contentsline {paragraph}{Forward 2-D wavelet transform basic step.}{55}{section*.28}
\contentsline {paragraph}{Fast 2-D wavelet transform.}{56}{section*.29}
\contentsline {paragraph}{Fast 2-D inverse wavelet transform.}{57}{section*.30}
\contentsline {section}{\numberline {3.6}Wavelet Design}{58}{section.3.6}
\contentsline {subsection}{\numberline {3.6.1}Low-pass Filter Constraints}{58}{subsection.3.6.1}
\contentsline {subsection}{\numberline {3.6.2}High-pass Filter Constraints}{60}{subsection.3.6.2}
\contentsline {paragraph}{Quadrature mirror filters.}{61}{section*.31}
\contentsline {subsection}{\numberline {3.6.3}Wavelet Design Constraints}{62}{subsection.3.6.3}
\contentsline {paragraph}{Vanishing moments.}{62}{section*.32}
\contentsline {paragraph}{Support.}{63}{section*.33}
\contentsline {paragraph}{Smoothness.}{63}{section*.34}
\contentsline {subsection}{\numberline {3.6.4}Daubechies Wavelets}{64}{subsection.3.6.4}
\contentsline {paragraph}{Wavelet display.}{65}{section*.35}
\contentsline {chapter}{\numberline {4}Linear and Non-linear Approximation}{67}{chapter.4}
\contentsline {section}{\numberline {4.1}Approximation}{67}{section.4.1}
\contentsline {subsection}{\numberline {4.1.1}Approximation in an Ortho-basis}{67}{subsection.4.1.1}
\contentsline {subsection}{\numberline {4.1.2}Linear Approximation}{67}{subsection.4.1.2}
\contentsline {subsection}{\numberline {4.1.3}Non-linear Approximation}{68}{subsection.4.1.3}
\contentsline {paragraph}{Computation of the threshold.}{68}{section*.36}
\contentsline {paragraph}{Hard thresholding.}{69}{section*.37}
\contentsline {section}{\numberline {4.2}Signal and Image Modeling}{69}{section.4.2}
\contentsline {subsection}{\numberline {4.2.1}Uniformly Smooth Signals and Images}{69}{subsection.4.2.1}
\contentsline {paragraph}{Signals with derivatives.}{69}{section*.38}
\contentsline {paragraph}{Sobolev smooth signals and images.}{70}{section*.39}
\contentsline {subsection}{\numberline {4.2.2}Piecewise Regular Signals and Images}{71}{subsection.4.2.2}
\contentsline {paragraph}{Piecewise smooth signals.}{71}{section*.40}
\contentsline {paragraph}{Piecewise smooth images.}{71}{section*.41}
\contentsline {subsection}{\numberline {4.2.3}Bounded Variation Signals and Images}{71}{subsection.4.2.3}
\contentsline {subsection}{\numberline {4.2.4}Cartoon Images}{72}{subsection.4.2.4}
\contentsline {section}{\numberline {4.3}Efficient approximation}{72}{section.4.3}
\contentsline {subsection}{\numberline {4.3.1}Decay of Approximation Error}{72}{subsection.4.3.1}
\contentsline {paragraph}{Polynomial error decay.}{73}{section*.42}
\contentsline {paragraph}{Relevance for compression, denoising and inverse problems.}{73}{section*.43}
\contentsline {paragraph}{Comparison of signals.}{73}{section*.44}
\contentsline {subsection}{\numberline {4.3.2}Comparison of bases.}{73}{subsection.4.3.2}
\contentsline {section}{\numberline {4.4}Fourier Linear Approximation of Smooth Functions}{74}{section.4.4}
\contentsline {subsection}{\numberline {4.4.1}1-D Fourier Approximation}{74}{subsection.4.4.1}
\contentsline {paragraph}{Low pass approximation.}{75}{section*.45}
\contentsline {subsection}{\numberline {4.4.2}Sobolev Images}{77}{subsection.4.4.2}
\contentsline {section}{\numberline {4.5}Wavelet Approximation of Piecewise Smooth Functions}{77}{section.4.5}
\contentsline {subsection}{\numberline {4.5.1}Decay of Wavelet Coefficients}{77}{subsection.4.5.1}
\contentsline {subsection}{\numberline {4.5.2}1-D Piecewise Smooth Approximation}{78}{subsection.4.5.2}
\contentsline {paragraph}{Step 1. Coefficient segmentation.}{79}{section*.46}
\contentsline {paragraph}{Step 2. Counting the error.}{79}{section*.47}
\contentsline {paragraph}{Step 3. Counting the number of measurements.}{80}{section*.48}
\contentsline {paragraph}{Step 3. Putting everything together.}{80}{section*.49}
\contentsline {subsection}{\numberline {4.5.3}2-D Piecewise Smooth Approximation}{80}{subsection.4.5.3}
\contentsline {section}{\numberline {4.6}Cartoon Images Approximation}{81}{section.4.6}
\contentsline {subsection}{\numberline {4.6.1}Wavelet Approximation of Cartoon Images}{81}{subsection.4.6.1}
\contentsline {subsection}{\numberline {4.6.2}Finite Element Approximation}{82}{subsection.4.6.2}
\contentsline {subsection}{\numberline {4.6.3}Curvelets Approximation}{83}{subsection.4.6.3}
\contentsline {paragraph}{Curvelets.}{83}{section*.50}
\contentsline {paragraph}{Parameter discretization.}{84}{section*.51}
\contentsline {paragraph}{Curvelet tight frame.}{85}{section*.52}
\contentsline {paragraph}{Curvelet approximation.}{85}{section*.53}
\contentsline {chapter}{\numberline {5}Compression}{87}{chapter.5}
\contentsline {section}{\numberline {5.1}Transform Coding}{87}{section.5.1}
\contentsline {subsection}{\numberline {5.1.1}Coding}{87}{subsection.5.1.1}
\contentsline {subsection}{\numberline {5.1.2}De-coding}{88}{subsection.5.1.2}
\contentsline {subsection}{\numberline {5.1.3}Support Coding}{88}{subsection.5.1.3}
\contentsline {paragraph}{Signals constraints.}{89}{section*.54}
\contentsline {paragraph}{Discrete computation and scaling of $N$.}{89}{section*.55}
\contentsline {paragraph}{Support coding.}{89}{section*.56}
\contentsline {paragraph}{Values coding.}{89}{section*.57}
\contentsline {paragraph}{Total number of bits.}{90}{section*.58}
\contentsline {section}{\numberline {5.2}Entropic Coding}{90}{section.5.2}
\contentsline {paragraph}{Probabilistic modeling.}{91}{section*.59}
\contentsline {paragraph}{Huffman code.}{91}{section*.60}
\contentsline {section}{\numberline {5.3}JPEG-2000}{91}{section.5.3}
\contentsline {paragraph}{Dyadic quantization.}{92}{section*.61}
\contentsline {paragraph}{Steam packing.}{92}{section*.62}
\contentsline {paragraph}{Bit plane coding pass.}{92}{section*.63}
\contentsline {paragraph}{Contextual coder.}{92}{section*.64}
\contentsline {chapter}{\numberline {6}Denoising}{95}{chapter.6}
\contentsline {section}{\numberline {6.1}Noise Modeling}{95}{section.6.1}
\contentsline {subsection}{\numberline {6.1.1}Noise in Images}{95}{subsection.6.1.1}
\contentsline {subsection}{\numberline {6.1.2}Image Formation}{96}{subsection.6.1.2}
\contentsline {paragraph}{Additive Noise.}{96}{section*.65}
\contentsline {subsection}{\numberline {6.1.3}Denoiser}{97}{subsection.6.1.3}
\contentsline {section}{\numberline {6.2}Linear Denoising using Filtering}{97}{section.6.2}
\contentsline {subsection}{\numberline {6.2.1}Translation Invariant Estimators}{97}{subsection.6.2.1}
\contentsline {subsection}{\numberline {6.2.2}Optimal Filter Selection}{98}{subsection.6.2.2}
\contentsline {subsection}{\numberline {6.2.3}Wiener Filter}{98}{subsection.6.2.3}
\contentsline {subsection}{\numberline {6.2.4}Denoising and Linear Approximation}{99}{subsection.6.2.4}
\contentsline {section}{\numberline {6.3}Non-linear Denoising using Thresholding}{102}{section.6.3}
\contentsline {subsection}{\numberline {6.3.1}Hard Thresholding}{102}{subsection.6.3.1}
\contentsline {subsection}{\numberline {6.3.2}Soft Thresholding}{103}{subsection.6.3.2}
\contentsline {paragraph}{Coarse scale management.}{104}{section*.66}
\contentsline {paragraph}{Empirical choice of the threshold.}{104}{section*.67}
\contentsline {subsection}{\numberline {6.3.3}Minimax Optimality of Thresholding}{104}{subsection.6.3.3}
\contentsline {paragraph}{Sparse coefficients estimation.}{104}{section*.68}
\contentsline {paragraph}{Universal threshold value.}{105}{section*.69}
\contentsline {paragraph}{Asymptotic optimality.}{105}{section*.70}
\contentsline {subsection}{\numberline {6.3.4}Translation Invariant Thresholding Estimators}{106}{subsection.6.3.4}
\contentsline {paragraph}{Translation invariance.}{106}{section*.71}
\contentsline {paragraph}{Cycle spinning.}{107}{section*.72}
\contentsline {paragraph}{Translation invariant wavelet frame.}{107}{section*.73}
\contentsline {subsection}{\numberline {6.3.5}Exotic Thresholdings}{108}{subsection.6.3.5}
\contentsline {paragraph}{Semi-soft thresholding.}{109}{section*.74}
\contentsline {paragraph}{Stein thresholding.}{109}{section*.75}
\contentsline {subsection}{\numberline {6.3.6}Block Thresholding}{109}{subsection.6.3.6}
\contentsline {section}{\numberline {6.4}Data-dependant Noises}{111}{section.6.4}
\contentsline {subsection}{\numberline {6.4.1}Poisson Noise}{112}{subsection.6.4.1}
\contentsline {paragraph}{Poisson model.}{112}{section*.76}
\contentsline {paragraph}{Variance stabilization.}{113}{section*.77}
\contentsline {subsection}{\numberline {6.4.2}Multiplicative Noise}{115}{subsection.6.4.2}
\contentsline {paragraph}{Multiplicative image formation.}{115}{section*.78}
\contentsline {chapter}{\numberline {7}Variational Priors and Regularization}{119}{chapter.7}
\contentsline {section}{\numberline {7.1}Sobolev and Total Variation Priors}{119}{section.7.1}
\contentsline {subsection}{\numberline {7.1.1}Continuous Priors}{119}{subsection.7.1.1}
\contentsline {paragraph}{Sobolev prior.}{119}{section*.79}
\contentsline {paragraph}{Total variation prior.}{119}{section*.80}
\contentsline {subsection}{\numberline {7.1.2}Discrete Priors}{119}{subsection.7.1.2}
\contentsline {paragraph}{Discrete gradient.}{120}{section*.81}
\contentsline {paragraph}{Discrete divergence.}{120}{section*.82}
\contentsline {paragraph}{Discrete laplacian.}{121}{section*.83}
\contentsline {paragraph}{Discrete energies.}{122}{section*.84}
\contentsline {section}{\numberline {7.2}PDE and Energy Minimization}{122}{section.7.2}
\contentsline {subsection}{\numberline {7.2.1}General Flows}{122}{subsection.7.2.1}
\contentsline {subsection}{\numberline {7.2.2}Heat Flow}{122}{subsection.7.2.2}
\contentsline {paragraph}{Continuous in space.}{123}{section*.85}
\contentsline {paragraph}{Discrete in space.}{123}{section*.86}
\contentsline {subsection}{\numberline {7.2.3}Total Variation Flows}{123}{subsection.7.2.3}
\contentsline {paragraph}{Total variation gradient.}{123}{section*.87}
\contentsline {paragraph}{Regularized total variation.}{124}{section*.88}
\contentsline {paragraph}{Regularized total variation flow.}{125}{section*.89}
\contentsline {subsection}{\numberline {7.2.4}PDE Flows for Denoising}{125}{subsection.7.2.4}
\contentsline {section}{\numberline {7.3}Regularization for Denoising}{126}{section.7.3}
\contentsline {subsection}{\numberline {7.3.1}Regularization}{126}{subsection.7.3.1}
\contentsline {subsection}{\numberline {7.3.2}Sobolev Regularization}{127}{subsection.7.3.2}
\contentsline {subsection}{\numberline {7.3.3}TV Regularization}{128}{subsection.7.3.3}
\contentsline {chapter}{\numberline {8}Inverse Problems}{131}{chapter.8}
\contentsline {section}{\numberline {8.1}Inverse Problems Regularization}{131}{section.8.1}
\contentsline {paragraph}{Denoising.}{131}{section*.90}
\contentsline {paragraph}{De-blurring and super-resolution.}{131}{section*.91}
\contentsline {paragraph}{Interpolation and inpainting.}{132}{section*.92}
\contentsline {paragraph}{Medical imaging.}{132}{section*.93}
\contentsline {paragraph}{Regression for supervised learning.}{132}{section*.94}
\contentsline {section}{\numberline {8.2}Theoretical Study of Quadratic Regularization}{133}{section.8.2}
\contentsline {subsection}{\numberline {8.2.1}Singular Value Decomposition}{133}{subsection.8.2.1}
\contentsline {paragraph}{Finite dimension.}{133}{section*.95}
\contentsline {paragraph}{Compact operators.}{134}{section*.96}
\contentsline {paragraph}{Pseudo inverse.}{134}{section*.97}
\contentsline {subsection}{\numberline {8.2.2}Tikonov Regularization}{135}{subsection.8.2.2}
\contentsline {paragraph}{Regularized inverse.}{135}{section*.98}
\contentsline {paragraph}{Variational regularization.}{135}{section*.99}
\contentsline {paragraph}{Source condition.}{136}{section*.100}
\contentsline {paragraph}{Sublinear convergence speed.}{136}{section*.101}
\contentsline {section}{\numberline {8.3}Quadratic Regularization}{138}{section.8.3}
\contentsline {paragraph}{Convex regularization.}{138}{section*.102}
\contentsline {paragraph}{Quadratic Regularization.}{139}{section*.103}
\contentsline {paragraph}{Example of convolution.}{139}{section*.104}
\contentsline {subsection}{\numberline {8.3.1}Solving Linear System}{140}{subsection.8.3.1}
\contentsline {section}{\numberline {8.4}Non-Quadratic Regularization}{140}{section.8.4}
\contentsline {subsection}{\numberline {8.4.1}Total Variation Regularization}{140}{subsection.8.4.1}
\contentsline {paragraph}{Total variation.}{141}{section*.105}
\contentsline {paragraph}{Discretized Total variation.}{141}{section*.106}
\contentsline {subsection}{\numberline {8.4.2}Gradient Descent Method}{142}{subsection.8.4.2}
\contentsline {subsection}{\numberline {8.4.3}Examples of Gradient Computation}{142}{subsection.8.4.3}
\contentsline {section}{\numberline {8.5}Examples of Inverse Problems}{143}{section.8.5}
\contentsline {subsection}{\numberline {8.5.1}Deconvolution}{143}{subsection.8.5.1}
\contentsline {subsection}{\numberline {8.5.2}Inpainting}{143}{subsection.8.5.2}
\contentsline {subsection}{\numberline {8.5.3}Tomography Inversion}{144}{subsection.8.5.3}
\contentsline {chapter}{\numberline {9}Sparse Regularization}{149}{chapter.9}
\contentsline {section}{\numberline {9.1}Sparsity Priors}{149}{section.9.1}
\contentsline {subsection}{\numberline {9.1.1}Ideal sparsity prior.}{149}{subsection.9.1.1}
\contentsline {subsection}{\numberline {9.1.2}Convex relaxation}{149}{subsection.9.1.2}
\contentsline {subsection}{\numberline {9.1.3}Sparse Regularization and Thresholding}{150}{subsection.9.1.3}
\contentsline {section}{\numberline {9.2}Sparse Regularization of Inverse Problems}{152}{section.9.2}
\contentsline {paragraph}{Analysis vs. synthesis priors.}{152}{section*.107}
\contentsline {section}{\numberline {9.3}Iterative Soft Thresholding Algorithm}{152}{section.9.3}
\contentsline {subsection}{\numberline {9.3.1}Noiseless Recovery as a Linear Program}{153}{subsection.9.3.1}
\contentsline {subsection}{\numberline {9.3.2}Projected Gradient Descent for $\ell ^1$.}{153}{subsection.9.3.2}
\contentsline {subsection}{\numberline {9.3.3}Iterative Soft Thresholding and Forward Backward}{154}{subsection.9.3.3}
\contentsline {section}{\numberline {9.4}Example: Sparse Deconvolution}{155}{section.9.4}
\contentsline {subsection}{\numberline {9.4.1}Sparse Spikes Deconvolution}{155}{subsection.9.4.1}
\contentsline {subsection}{\numberline {9.4.2}Sparse Wavelets Deconvolution}{155}{subsection.9.4.2}
\contentsline {subsection}{\numberline {9.4.3}Sparse Inpainting}{156}{subsection.9.4.3}
\contentsline {chapter}{\numberline {10}Theory of Sparse Regularization}{161}{chapter.10}
\contentsline {section}{\numberline {10.1}Existence and Uniqueness}{161}{section.10.1}
\contentsline {subsection}{\numberline {10.1.1}Existence}{161}{subsection.10.1.1}
\contentsline {subsection}{\numberline {10.1.2}Polytope Projection for the Constraint Problem}{161}{subsection.10.1.2}
\contentsline {subsection}{\numberline {10.1.3}Optimality Conditions}{163}{subsection.10.1.3}
\contentsline {subsection}{\numberline {10.1.4}Uniqueness}{164}{subsection.10.1.4}
\contentsline {subsection}{\numberline {10.1.5}Duality}{165}{subsection.10.1.5}
\contentsline {section}{\numberline {10.2}Consistency and Sparsitency}{166}{section.10.2}
\contentsline {subsection}{\numberline {10.2.1}Bregman Divergence Rates for General Regularizations}{166}{subsection.10.2.1}
\contentsline {subsection}{\numberline {10.2.2}Linear Rates in Norms for $\ell ^1$ Regularization}{168}{subsection.10.2.2}
\contentsline {subsection}{\numberline {10.2.3}Sparsistency for Low Noise}{169}{subsection.10.2.3}
\contentsline {subsection}{\numberline {10.2.4}Sparsistency for Arbitrary Noise}{172}{subsection.10.2.4}
\contentsline {section}{\numberline {10.3}Sparse Deconvolution Case Study}{172}{section.10.3}
\contentsline {chapter}{\numberline {11}Compressed Sensing}{177}{chapter.11}
\contentsline {section}{\numberline {11.1}Motivation and Potential Applications}{177}{section.11.1}
\contentsline {subsection}{\numberline {11.1.1}Single Pixel Camera}{177}{subsection.11.1.1}
\contentsline {subsection}{\numberline {11.1.2}Sparse Recovery}{178}{subsection.11.1.2}
\contentsline {section}{\numberline {11.2}Dual Certificate Theory and Non-Uniform Guarantees}{179}{section.11.2}
\contentsline {subsection}{\numberline {11.2.1}Random Projection of Polytopes}{179}{subsection.11.2.1}
\contentsline {subsection}{\numberline {11.2.2}Random Matrices}{179}{subsection.11.2.2}
\contentsline {paragraph}{Linear growth $P = s/\beta $. }{179}{section*.108}
\contentsline {paragraph}{Super-linear grows $P = s \qopname \relax o{log}(\ldots )$. }{179}{section*.109}
\contentsline {subsection}{\numberline {11.2.3}Dual Certificates}{181}{subsection.11.2.3}
\contentsline {paragraph}{Coherence-based analysis.}{181}{section*.110}
\contentsline {paragraph}{Randomized analysis of the Fuchs certificate.}{182}{section*.111}
\contentsline {section}{\numberline {11.3}RIP Theory for Uniform Guarantees}{184}{section.11.3}
\contentsline {subsection}{\numberline {11.3.1}Restricted Isometry Constants}{184}{subsection.11.3.1}
\contentsline {subsection}{\numberline {11.3.2}RIP implies dual certificates}{185}{subsection.11.3.2}
\contentsline {subsection}{\numberline {11.3.3}RIP implies stable recovery}{187}{subsection.11.3.3}
\contentsline {subsection}{\numberline {11.3.4}Fourier sampling RIP}{188}{subsection.11.3.4}
\contentsline {chapter}{\numberline {12}Basics of Machine Learning}{191}{chapter.12}
\contentsline {section}{\numberline {12.1}Unsupervised Learning}{191}{section.12.1}
\contentsline {subsection}{\numberline {12.1.1}Dimensionality Reduction and PCA}{191}{subsection.12.1.1}
\contentsline {paragraph}{Presentation of the method.}{191}{section*.112}
\contentsline {paragraph}{Optimality analysis.}{192}{section*.113}
\contentsline {subsection}{\numberline {12.1.2}Clustering and $k$-means}{195}{subsection.12.1.2}
\contentsline {paragraph}{$k$-means}{195}{section*.114}
\contentsline {paragraph}{$k$-means++}{195}{section*.115}
\contentsline {paragraph}{Lloyd algorithm and continuous densities.}{196}{section*.116}
\contentsline {section}{\numberline {12.2}Empirical Risk Minimization}{196}{section.12.2}
\contentsline {subsection}{\numberline {12.2.1}Empirical Risk}{197}{subsection.12.2.1}
\contentsline {subsection}{\numberline {12.2.2}Prediction and Consistency}{197}{subsection.12.2.2}
\contentsline {subsection}{\numberline {12.2.3}Parametric Approaches and Regularization}{198}{subsection.12.2.3}
\contentsline {paragraph}{Prediction vs. estimation risks.}{198}{section*.117}
\contentsline {subsection}{\numberline {12.2.4}Testing Set and Cross-validation}{198}{subsection.12.2.4}
\contentsline {section}{\numberline {12.3}Supervised Learning: Regression}{198}{section.12.3}
\contentsline {subsection}{\numberline {12.3.1}Linear Regression}{199}{subsection.12.3.1}
\contentsline {paragraph}{Least square and conditional expectation.}{199}{section*.118}
\contentsline {paragraph}{Penalized linear models.}{200}{figure.12.10}
\contentsline {paragraph}{Ridge regression (quadratic penalization).}{201}{section*.120}
\contentsline {section}{\numberline {12.4}Supervised Learning: Classification}{201}{section.12.4}
\contentsline {subsection}{\numberline {12.4.1}Nearest Neighbors Classification}{201}{subsection.12.4.1}
\contentsline {subsection}{\numberline {12.4.2}Two Classes Logistic Classification}{202}{subsection.12.4.2}
\contentsline {paragraph}{Approximate risk minimization.}{202}{section*.121}
\contentsline {paragraph}{Logistic loss probabilistic interpretation.}{203}{section*.122}
\contentsline {paragraph}{Gradient descent method.}{204}{section*.123}
\contentsline {subsection}{\numberline {12.4.3}Multi-Classes Logistic Classification}{205}{subsection.12.4.3}
\contentsline {section}{\numberline {12.5}Kernel Methods}{206}{section.12.5}
\contentsline {subsection}{\numberline {12.5.1}Reproducing Kernel Hilbert Space}{207}{subsection.12.5.1}
\contentsline {subsection}{\numberline {12.5.2}Examples of Kernelized Algorithms}{208}{subsection.12.5.2}
\contentsline {paragraph}{Kernelized ridge regression.}{208}{section*.124}
\contentsline {paragraph}{Kernelized logistic classification.}{209}{section*.125}
\contentsline {paragraph}{Kernelized nearest-neihbors. }{209}{section*.126}
\contentsline {paragraph}{Kernel on strings. }{209}{section*.127}
\contentsline {chapter}{\numberline {13}Optimization \& Machine Learning: Smooth Optimization}{211}{chapter.13}
\contentsline {section}{\numberline {13.1}Motivation in Machine Learning}{211}{section.13.1}
\contentsline {subsection}{\numberline {13.1.1}Unconstraint optimization}{211}{subsection.13.1.1}
\contentsline {subsection}{\numberline {13.1.2}Regression}{212}{subsection.13.1.2}
\contentsline {subsection}{\numberline {13.1.3}Classification}{212}{subsection.13.1.3}
\contentsline {section}{\numberline {13.2}Basics of Convex Analysis}{212}{section.13.2}
\contentsline {subsection}{\numberline {13.2.1}Existence of Solutions}{212}{subsection.13.2.1}
\contentsline {subsection}{\numberline {13.2.2}Convexity}{213}{subsection.13.2.2}
\contentsline {paragraph}{Strict convexity.}{213}{section*.128}
\contentsline {subsection}{\numberline {13.2.3}Convex Sets}{214}{subsection.13.2.3}
\contentsline {section}{\numberline {13.3}Derivative and gradient}{214}{section.13.3}
\contentsline {subsection}{\numberline {13.3.1}Gradient}{214}{subsection.13.3.1}
\contentsline {subsection}{\numberline {13.3.2}First Order Conditions}{215}{subsection.13.3.2}
\contentsline {subsection}{\numberline {13.3.3}Least Squares}{216}{subsection.13.3.3}
\contentsline {subsection}{\numberline {13.3.4}Link with PCA}{217}{subsection.13.3.4}
\contentsline {subsection}{\numberline {13.3.5}Classification}{218}{subsection.13.3.5}
\contentsline {subsection}{\numberline {13.3.6}Chain Rule}{218}{subsection.13.3.6}
\contentsline {section}{\numberline {13.4}Gradient Descent Algorithm}{219}{section.13.4}
\contentsline {subsection}{\numberline {13.4.1}Steepest Descent Direction}{219}{subsection.13.4.1}
\contentsline {subsection}{\numberline {13.4.2}Gradient Descent}{220}{subsection.13.4.2}
\contentsline {section}{\numberline {13.5}Convergence Analysis}{221}{section.13.5}
\contentsline {subsection}{\numberline {13.5.1}Quadratic Case}{221}{subsection.13.5.1}
\contentsline {paragraph}{Convergence analysis for the quadratic case.}{221}{section*.129}
\contentsline {subsection}{\numberline {13.5.2}General Case}{223}{subsection.13.5.2}
\contentsline {paragraph}{Hessian.}{223}{section*.130}
\contentsline {paragraph}{Smoothness and strong convexity.}{225}{section*.131}
\contentsline {paragraph}{Convergence analysis.}{225}{section*.132}
\contentsline {chapter}{\numberline {14}Optimization \& Machine Learning: Advanced Topics}{229}{chapter.14}
\contentsline {section}{\numberline {14.1}Regularization}{229}{section.14.1}
\contentsline {subsection}{\numberline {14.1.1}Penalized Least Squares}{229}{subsection.14.1.1}
\contentsline {subsection}{\numberline {14.1.2}Ridge Regression}{229}{subsection.14.1.2}
\contentsline {paragraph}{Pseudo-inverse.}{230}{section*.133}
\contentsline {subsection}{\numberline {14.1.3}Lasso}{231}{subsection.14.1.3}
\contentsline {subsection}{\numberline {14.1.4}Iterative Soft Thresholding}{231}{subsection.14.1.4}
\contentsline {section}{\numberline {14.2}Stochastic Optimization}{232}{section.14.2}
\contentsline {subsection}{\numberline {14.2.1}Minimizing Sums and Expectation}{233}{subsection.14.2.1}
\contentsline {subsection}{\numberline {14.2.2}Batch Gradient Descent (BGD)}{233}{subsection.14.2.2}
\contentsline {subsection}{\numberline {14.2.3}Stochastic Gradient Descent (SGD)}{234}{subsection.14.2.3}
\contentsline {subsection}{\numberline {14.2.4}Stochastic Gradient Descent with Averaging (SGA)}{236}{subsection.14.2.4}
\contentsline {subsection}{\numberline {14.2.5}Stochastic Averaged Gradient Descent (SAG)}{237}{subsection.14.2.5}
\contentsline {section}{\numberline {14.3}Automatic Differentiation}{237}{section.14.3}
\contentsline {subsection}{\numberline {14.3.1}Finite Differences and Symbolic Calculus}{238}{subsection.14.3.1}
\contentsline {subsection}{\numberline {14.3.2}Computational Graphs}{238}{subsection.14.3.2}
\contentsline {subsection}{\numberline {14.3.3}Forward Mode of Automatic Differentiation}{238}{subsection.14.3.3}
\contentsline {paragraph}{Simple example.}{239}{section*.134}
\contentsline {paragraph}{Dual numbers.}{240}{section*.135}
\contentsline {subsection}{\numberline {14.3.4}Reverse Mode of Automatic Differentiation}{241}{subsection.14.3.4}
\contentsline {paragraph}{Back-propagation.}{241}{section*.136}
\contentsline {paragraph}{Simple example.}{241}{section*.137}
\contentsline {subsection}{\numberline {14.3.5}Feed-forward Compositions}{242}{subsection.14.3.5}
\contentsline {subsection}{\numberline {14.3.6}Feed-forward Architecture}{242}{subsection.14.3.6}
\contentsline {paragraph}{Multilayers perceptron.}{243}{section*.138}
\contentsline {paragraph}{Link with adjoint state method.}{243}{section*.139}
\contentsline {subsection}{\numberline {14.3.7}Recurrent Architectures}{244}{subsection.14.3.7}
\contentsline {paragraph}{Residual recurrent networks. }{244}{section*.140}
\contentsline {paragraph}{Mitigating memory requirement. }{244}{section*.141}
\contentsline {paragraph}{Fixed point maps}{245}{section*.142}
\contentsline {paragraph}{Argmin layers}{245}{section*.143}
\contentsline {paragraph}{Sinkhorn's algorithm}{246}{section*.144}
\contentsline {chapter}{\numberline {15}Deep Learning}{247}{chapter.15}
\contentsline {section}{\numberline {15.1}Multi-Layers Perceptron}{247}{section.15.1}
\contentsline {subsection}{\numberline {15.1.1}MLP and its derivative}{247}{subsection.15.1.1}
\contentsline {paragraph}{Expressiveness. }{248}{section*.145}
\contentsline {subsection}{\numberline {15.1.2}MLP and Gradient Computation}{248}{subsection.15.1.2}
\contentsline {paragraph}{Optimizing with respect to $u$.}{248}{section*.146}
\contentsline {paragraph}{Optimizing with respect to $W$.}{248}{section*.147}
\contentsline {subsection}{\numberline {15.1.3}Universality}{249}{subsection.15.1.3}
\contentsline {paragraph}{Proof in dimension $p=1$.}{249}{section*.148}
\contentsline {paragraph}{Proof in arbitrary dimension $p$.}{249}{section*.149}
\contentsline {paragraph}{Quantitative rates.}{251}{section*.150}
\contentsline {section}{\numberline {15.2}Deep Discriminative Models}{251}{section.15.2}
\contentsline {subsection}{\numberline {15.2.1}Deep Network Structure}{251}{subsection.15.2.1}
\contentsline {subsection}{\numberline {15.2.2}Perceptron and Shallow Models}{252}{subsection.15.2.2}
\contentsline {subsection}{\numberline {15.2.3}Convolutional Neural Networks}{253}{subsection.15.2.3}
\contentsline {subsection}{\numberline {15.2.4}Scattering Transform}{254}{subsection.15.2.4}
\contentsline {chapter}{\numberline {16}Convex Analysis}{255}{chapter.16}
\contentsline {section}{\numberline {16.1}Basics of Convex Analysis}{255}{section.16.1}
\contentsline {subsection}{\numberline {16.1.1}Convex Sets and Functions}{255}{subsection.16.1.1}
\contentsline {subsection}{\numberline {16.1.2}First Order Conditions}{256}{subsection.16.1.2}
\contentsline {paragraph}{Existence of minimizers.}{256}{section*.151}
\contentsline {paragraph}{Sub-differential.}{256}{section*.152}
\contentsline {paragraph}{First Order Conditions.}{257}{section*.153}
\contentsline {paragraph}{Sub-differential calculus.}{257}{section*.154}
\contentsline {paragraph}{Normal cone.}{258}{section*.155}
\contentsline {section}{\numberline {16.2}Convex Duality}{258}{section.16.2}
\contentsline {subsection}{\numberline {16.2.1}Lagrange Duality}{258}{subsection.16.2.1}
\contentsline {subsection}{\numberline {16.2.2}Legendre-Fenchel Transform}{260}{subsection.16.2.2}
\contentsline {paragraph}{Legendre transform and smoothness.}{261}{section*.156}
\contentsline {subsection}{\numberline {16.2.3}Fenchel-Rockafellar Duality}{262}{subsection.16.2.3}
\contentsline {chapter}{\numberline {17}Non-smooth Convex Optimization}{263}{chapter.17}
\contentsline {section}{\numberline {17.1}Descent Methods}{263}{section.17.1}
\contentsline {subsection}{\numberline {17.1.1}Gradient Descent}{263}{subsection.17.1.1}
\contentsline {subsection}{\numberline {17.1.2}Sub-gradient Descent}{263}{subsection.17.1.2}
\contentsline {subsection}{\numberline {17.1.3}Projected Gradient Descent}{264}{subsection.17.1.3}
\contentsline {section}{\numberline {17.2}Proximal Algorithm}{264}{section.17.2}
\contentsline {subsection}{\numberline {17.2.1}Proximal Map }{264}{subsection.17.2.1}
\contentsline {paragraph}{Examples}{265}{section*.157}
\contentsline {subsection}{\numberline {17.2.2}Basic Properties}{265}{subsection.17.2.2}
\contentsline {subsection}{\numberline {17.2.3}Related Concepts}{266}{subsection.17.2.3}
\contentsline {paragraph}{Link with sub-differential.}{266}{section*.158}
\contentsline {paragraph}{Link with duality.}{266}{section*.159}
\contentsline {paragraph}{Link with Moreau-Yosida regularization.}{267}{section*.160}
\contentsline {section}{\numberline {17.3}Primal Algorithms}{267}{section.17.3}
\contentsline {subsection}{\numberline {17.3.1}Proximal Point Algorithm}{267}{subsection.17.3.1}
\contentsline {subsection}{\numberline {17.3.2}Forward-Backward}{267}{subsection.17.3.2}
\contentsline {paragraph}{Derivation using surrogate functionals.}{268}{section*.161}
\contentsline {paragraph}{Convergence of FB. }{268}{section*.162}
\contentsline {subsection}{\numberline {17.3.3}Douglas-Rachford}{269}{subsection.17.3.3}
\contentsline {paragraph}{More than two functions.}{269}{section*.163}
\contentsline {paragraph}{Handling a linear operator.}{269}{section*.164}
\contentsline {section}{\numberline {17.4}Dual and Primal-Dual Algorithms}{270}{section.17.4}
\contentsline {subsection}{\numberline {17.4.1}Forward-backward on the Dual}{270}{subsection.17.4.1}
\contentsline {subsection}{\numberline {17.4.2}Primal-Dual Splitting}{271}{subsection.17.4.2}
