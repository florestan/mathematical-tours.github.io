\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\zref@newlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {13}Optimization \& Machine Learning: Smooth Optimization}{215}{chapter.13}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{c-smooth-optim}{{13}{215}{Optimization \& Machine Learning: Smooth Optimization}{chapter.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {13.1}Motivation in Machine Learning}{215}{section.13.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.1.1}Unconstraint optimization}{215}{subsection.13.1.1}}
\newlabel{eq-general-pbm}{{13.1}{215}{Unconstraint optimization}{equation.13.1.1}{}}
\newlabel{eq-general-pbm-min}{{13.2}{215}{Unconstraint optimization}{equation.13.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.1}{\ignorespaces  Left: linear regression, middle: linear classifier, right: loss function for classification. }}{215}{figure.13.1}}
\newlabel{fig-ml-ex}{{13.1}{215}{Left: linear regression, middle: linear classifier, right: loss function for classification}{figure.13.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.2}{\ignorespaces  Left: non-existence of minimizer, middle: multiple minimizers, right: uniqueness. }}{216}{figure.13.2}}
\newlabel{fig-minimizer-exists}{{13.2}{216}{Left: non-existence of minimizer, middle: multiple minimizers, right: uniqueness}{figure.13.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.1.2}Regression}{216}{subsection.13.1.2}}
\newlabel{eq-least-square}{{13.3}{216}{Regression}{equation.13.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.1.3}Classification}{216}{subsection.13.1.3}}
\newlabel{eq-classif}{{13.4}{216}{Classification}{equation.13.1.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {13.2}Basics of Convex Analysis}{216}{section.13.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.2.1}Existence of Solutions}{216}{subsection.13.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.3}{\ignorespaces  Coercivity condition for least squares. }}{217}{figure.13.3}}
\newlabel{fig-least-square}{{13.3}{217}{Coercivity condition for least squares}{figure.13.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.4}{\ignorespaces  Convex vs. non-convex functions ; Strictly convex vs. non strictly convex functions. }}{217}{figure.13.4}}
\newlabel{fig-cvx-vs-noncvx}{{13.4}{217}{Convex vs. non-convex functions ; Strictly convex vs. non strictly convex functions}{figure.13.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.2.2}Convexity}{217}{subsection.13.2.2}}
\newlabel{eq-convexity-def}{{13.5}{217}{Convexity}{equation.13.2.5}{}}
\@writefile{toc}{\contentsline {paragraph}{Strict convexity.}{217}{section*.133}}
\newlabel{eq-strict-convexity-def}{{13.6}{217}{Strict convexity}{equation.13.2.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.5}{\ignorespaces  Comparison of convex functions $f : \mathbb  {R}^p \rightarrow \mathbb  {R}$ (for $p=1$) and convex sets $C \subset \mathbb  {R}^p$ (for $p=2$). }}{218}{figure.13.5}}
\newlabel{fig-cvx-set}{{13.5}{218}{Comparison of convex functions $f : \RR ^p \rightarrow \RR $ (for $p=1$) and convex sets $C \subset \RR ^p$ (for $p=2$)}{figure.13.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.2.3}Convex Sets}{218}{subsection.13.2.3}}
\@writefile{toc}{\contentsline {section}{\numberline {13.3}Derivative and gradient}{218}{section.13.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.3.1}Gradient}{218}{subsection.13.3.1}}
\newlabel{eq-grad-dfn}{{13.7}{218}{Gradient}{equation.13.3.7}{}}
\newlabel{prop-above-tgt}{{41}{219}{}{prop.41}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.3.2}First Order Conditions}{219}{subsection.13.3.2}}
\newlabel{prop-cs-min}{{42}{219}{}{prop.42}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.6}{\ignorespaces  Function with local maxima/minima (left), saddle point (middle) and global minimum (right). }}{220}{figure.13.6}}
\newlabel{fig-first-order}{{13.6}{220}{Function with local maxima/minima (left), saddle point (middle) and global minimum (right)}{figure.13.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.3.3}Least Squares}{220}{subsection.13.3.3}}
\newlabel{eq-grad-ls}{{13.8}{220}{Least Squares}{equation.13.3.8}{}}
\newlabel{eq-sol-leastsquare}{{13.9}{220}{Least Squares}{equation.13.3.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.7}{\ignorespaces  Left: point clouds $(a_i)_i$ with associated PCA directions, right: quadratic part of $f(x)$. }}{221}{figure.13.7}}
\newlabel{fig-link-pca}{{13.7}{221}{Left: point clouds $(a_i)_i$ with associated PCA directions, right: quadratic part of $f(x)$}{figure.13.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.3.4}Link with PCA}{221}{subsection.13.3.4}}
\newlabel{eq-pca-decomp}{{13.10}{221}{Link with PCA}{equation.13.3.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.3.5}Classification}{222}{subsection.13.3.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.3.6}Chain Rule}{222}{subsection.13.3.6}}
\newlabel{eq-grad-composition-linear}{{13.11}{222}{Chain Rule}{equation.13.3.11}{}}
\newlabel{eq-differential-defn}{{13.12}{222}{Chain Rule}{equation.13.3.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.8}{\ignorespaces  Left: First order Taylor expansion in 1-D and 2-D. Right: orthogonality of gradient and level sets and schematic of the proof. }}{223}{figure.13.8}}
\newlabel{fig-expansion-taylor}{{13.8}{223}{Left: First order Taylor expansion in 1-D and 2-D. Right: orthogonality of gradient and level sets and schematic of the proof}{figure.13.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {13.4}Gradient Descent Algorithm}{223}{section.13.4}}
\newlabel{sec-grad-desc-basic}{{13.4}{223}{Gradient Descent Algorithm}{section.13.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.4.1}Steepest Descent Direction}{223}{subsection.13.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.9}{\ignorespaces  Influence of $\tau $ on the gradient descent (left) and optimal step size choice (right). }}{224}{figure.13.9}}
\newlabel{fig-gradesc}{{13.9}{224}{Influence of $\tau $ on the gradient descent (left) and optimal step size choice (right)}{figure.13.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.4.2}Gradient Descent}{224}{subsection.13.4.2}}
\newlabel{eq-grad-desc}{{13.13}{224}{Gradient Descent}{equation.13.4.13}{}}
\newlabel{eq-armijo-rule}{{13.14}{225}{Armijo rule}{equation.13.4.14}{}}
\@writefile{toc}{\contentsline {section}{\numberline {13.5}Convergence Analysis}{225}{section.13.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.5.1}Quadratic Case}{225}{subsection.13.5.1}}
\@writefile{toc}{\contentsline {paragraph}{Convergence analysis for the quadratic case.}{225}{section*.134}}
\newlabel{prop-graddesc-quad}{{44}{225}{}{prop.44}{}}
\newlabel{eq-global-linrate-grad}{{13.15}{225}{}{equation.13.5.15}{}}
\newlabel{eq-best-rate-local}{{13.16}{225}{}{equation.13.5.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.10}{\ignorespaces  Contraction constant $h(\tau )$ for a quadratic function (right). }}{226}{figure.13.10}}
\newlabel{fig-grad-desc-contract}{{13.10}{226}{Contraction constant $h(\tau )$ for a quadratic function (right)}{figure.13.10}{}}
\newlabel{eq-rate-strong-quad}{{13.17}{226}{Convergence analysis for the quadratic case}{equation.13.5.17}{}}
\newlabel{prop-graddesc-quad-sublin}{{45}{227}{}{prop.45}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.5.2}General Case}{228}{subsection.13.5.2}}
\@writefile{toc}{\contentsline {paragraph}{Hessian.}{228}{section*.135}}
\newlabel{eq-taylor-hess}{{13.18}{228}{Hessian}{equation.13.5.18}{}}
\@writefile{toc}{\contentsline {paragraph}{Smoothness and strong convexity.}{229}{section*.136}}
\newlabel{eq-lipsch-grad}{{{$\mathcal  {R}_L$}}{229}{Smoothness and strong convexity}{equation.13.5.19}{}}
\newlabel{eq-strong-conv}{{{$\mathcal  {S}_\mu $}}{229}{Smoothness and strong convexity}{equation.13.5.19}{}}
\newlabel{prop-smooth-strong}{{46}{229}{}{prop.46}{}}
\newlabel{eq-above-below-quad}{{13.19}{229}{}{equation.13.5.19}{}}
\newlabel{eq-upper-lower-bound-hess}{{13.20}{229}{}{equation.13.5.20}{}}
\@writefile{toc}{\contentsline {paragraph}{Convergence analysis.}{230}{section*.137}}
\newlabel{thm-gradsec-non-strong-conv}{{24}{230}{}{thm.24}{}}
\newlabel{eq-sublin-rate-gd}{{13.21}{230}{}{equation.13.5.21}{}}
\newlabel{eq-proox-x'rad-nonstrong-1}{{13.22}{230}{Convergence analysis}{equation.13.5.22}{}}
\newlabel{eq-conv-rate-proof-1}{{13.25}{230}{Convergence analysis}{equation.13.5.25}{}}
\newlabel{eq-rate-strong}{{13.26}{231}{Convergence analysis}{equation.13.5.26}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.5.3}Acceleration}{231}{subsection.13.5.3}}
\@setckpt{chapters/optim-ml-smooth}{
\setcounter{page}{233}
\setcounter{equation}{26}
\setcounter{enumi}{3}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{13}
\setcounter{section}{5}
\setcounter{subsection}{3}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{10}
\setcounter{table}{0}
\setcounter{Item}{3}
\setcounter{Hfootnote}{3}
\setcounter{bookmark@seq@number}{217}
\setcounter{parentequation}{0}
\setcounter{subfigure}{0}
\setcounter{lofdepth}{1}
\setcounter{subtable}{0}
\setcounter{lotdepth}{1}
\setcounter{thm}{24}
\setcounter{prop}{46}
\setcounter{defn}{1}
\setcounter{cor}{0}
\setcounter{alg}{0}
\setcounter{lem}{9}
\setcounter{rem}{9}
\setcounter{exmp}{8}
\setcounter{float@type}{32}
\setcounter{listing}{0}
\setcounter{lstnumber}{1}
\setcounter{mdf@globalstyle@cnt}{0}
\setcounter{mdfcountframes}{0}
\setcounter{mdf@env@i}{0}
\setcounter{mdf@env@ii}{0}
\setcounter{mdf@zref@counter}{0}
\setcounter{AM@survey}{0}
\setcounter{section@level}{2}
\setcounter{lstlisting}{0}
}
